# services/task_generator_service.py
"""
Emotion ê¸°ë°˜ ê³¼ì œ ìƒì„± ì„œë¹„ìŠ¤
- ì„¸ì…˜ ê¸°ë°˜ ê°ì • ë¶„ì„ì„ í†µí•´ 5ê°œ emotionê³¼ score ì¶”ì¶œ
- ë…¼ë¬¸ ì²­í¬ ê²€ìƒ‰ ë° LangChainì„ ì‚¬ìš©í•˜ì—¬ ê³¼ì œ(task)ì™€ í•µì‹¬ íš¨ê³¼(core_effect) ìƒì„±
"""

from typing import List, Dict, Any, Optional
import json
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from app.config import get_settings
from app.utils.pdf_to_vector import get_pg_conn, load_embedder
from app.services.chat_session import ChatSessionManager, get_session_manager
from app.services.emotion_service import EmotionService, get_emotion_service


class TaskGeneratorService:
    """
    Emotion ê¸°ë°˜ ê³¼ì œ ìƒì„± ì„œë¹„ìŠ¤
    - ì„¸ì…˜ ê¸°ë°˜ ê°ì • ë¶„ì„ì„ í†µí•´ 5ê°œ emotionê³¼ score ì¶”ì¶œ
    - PostgreSQL + pgvectorì—ì„œ ë…¼ë¬¸ ì²­í¬ ê²€ìƒ‰
    - LangChainìœ¼ë¡œ ê³¼ì œ ìƒì„±
    """
    
    def __init__(
        self,
        table_name: str = "thesis_chunks",
        session_manager: Optional[ChatSessionManager] = None,
        emotion_service: Optional[EmotionService] = None
    ):
        """
        ì´ˆê¸°í™”
        
        Args:
            table_name: ê²€ìƒ‰í•  í…Œì´ë¸” ì´ë¦„ (ê¸°ë³¸ê°’: thesis_chunks)
            session_manager: ì„¸ì…˜ ê´€ë¦¬ì (ì„ íƒ, ì—†ìœ¼ë©´ ì‹±ê¸€í†¤ ì‚¬ìš©)
            emotion_service: ê°ì • ë¶„ì„ ì„œë¹„ìŠ¤ (ì„ íƒ, ì—†ìœ¼ë©´ ì‹±ê¸€í†¤ ì‚¬ìš©)
        """
        settings = get_settings()
        self.openai_api_key = settings.openai_api_key
        self.database_url = settings.database_url
        self.table_name = table_name
        
        # ì„¸ì…˜ ê´€ë¦¬ì ë° ê°ì • ë¶„ì„ ì„œë¹„ìŠ¤
        self.session_manager = session_manager or get_session_manager()
        self.emotion_service = emotion_service or get_emotion_service()
        
        # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
        self.embedder, self.dim = load_embedder()
        
        # LLM ëª¨ë¸ ì„¤ì •
        self.llm = ChatOpenAI(
            model="gpt-4o-mini",
            api_key=self.openai_api_key,
            temperature=0.7
        )
        
        # System Prompt ì„¤ì •
        self.system_prompt = (
            "ë‹¹ì‹ ì€ ìš°ìš¸ì¦ì„ ê²ªëŠ” ì‚¬ìš©ìì—ê²Œ ë”°ëœ»í•œ ê³µê°ê³¼ í•¨ê»˜ ì‹¤ì§ˆì ì¸ í–‰ë™ ê³¼ì œë¥¼ ì œì‹œí•˜ëŠ” ì‹¬ë¦¬í•™ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
            "ë‹µë³€ì€ ì¹œì ˆí•˜ê³  ê²©ë ¤í•˜ëŠ” êµ¬ì–´ì²´ë¡œ ì‘ì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. "
            "ì‚¬ìš©ìê°€ ì œê³µí•œ ë…¼ë¬¸(ì²­í¬) ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ, "
            "'8ê°œì˜ í•µì‹¬ ì¹˜ë£Œ ê¸°ë²•' í•­ëª©ì„ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ê³¼ì œ(Task)ë¥¼ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤. "
            "ë˜í•œ, ì´ ê³¼ì œ ìˆ˜í–‰ìœ¼ë¡œ ì–»ì„ ìˆ˜ ìˆëŠ” 'í•µì‹¬ íš¨ê³¼(Core Effect)'ë¥¼ ë…¼ë¬¸ ë‚´ìš©ê³¼ ì—°ê²°í•˜ì—¬ ì„¤ëª…í•˜ì‹­ì‹œì˜¤.\n\n"
            "ì¶œë ¥ì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ë§Œì„ ë”°ë¥´ì‹­ì‹œì˜¤.\n\n"
            "{\n"
            '  "task": "ì‚¬ìš©ìê°€ ì‹¤ì²œí•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ í–‰ë™ ê³¼ì œ",\n'
            '  "core_effect": "í•´ë‹¹ ê³¼ì œë¥¼ í†µí•´ ê¸°ëŒ€ë˜ëŠ” í•µì‹¬ ì‹¬ë¦¬ì  íš¨ê³¼"\n'
            "}"
        )
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„± (LangChain)
        self.prompt_template = ChatPromptTemplate.from_messages([
            ("system", self.system_prompt),
            ("human", """ì‚¬ìš©ì ì§ˆë¬¸: {user_query}

ì‚¬ìš©ìì˜ ê°ì • ìƒíƒœ:
{emotions_info}

ì°¸ê³  ë…¼ë¬¸ ë‚´ìš©:
{context_text}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ JSON í˜•ì‹ìœ¼ë¡œ ê³¼ì œì™€ í•µì‹¬ íš¨ê³¼ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.""")
        ])
        
        # LangChain ì²´ì¸ êµ¬ì„± (LCEL)
        self.chain = (
            self.prompt_template
            | self.llm
            | StrOutputParser()
        )
    
    def search_thesis_chunks(
        self,
        query: str,
        k: int = 2
    ) -> str:
        """
        PostgreSQL + pgvectorì—ì„œ ë…¼ë¬¸ ì²­í¬ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬ í…ìŠ¤íŠ¸
            k: ë°˜í™˜í•  ìƒìœ„ Kê°œ ê²°ê³¼
        
        Returns:
            ê²€ìƒ‰ëœ ì²­í¬ë“¤ì„ ê²°í•©í•œ í…ìŠ¤íŠ¸
        """
        try:
            conn = get_pg_conn(self.database_url)
        except Exception as e:
            print(f"âŒ PostgreSQL ì—°ê²° ì˜¤ë¥˜: {e}")
            return ""
        
        try:
            # í…Œì´ë¸” ì¡´ì¬ í™•ì¸
            with conn.cursor() as cur:
                cur.execute(f"""
                    SELECT EXISTS (
                        SELECT FROM information_schema.tables 
                        WHERE table_name = %s
                    );
                """, (self.table_name,))
                table_exists = cur.fetchone()[0]
                
                if not table_exists:
                    print(f"âŒ ì˜¤ë¥˜: í…Œì´ë¸” '{self.table_name}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    conn.close()
                    return ""
            
            # ì¿¼ë¦¬ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
            query_embedding = self.embedder.embed_query(query)
            vec_literal = "[" + ",".join(f"{x:.6f}" for x in query_embedding) + "]"
            
            # ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹¤í–‰
            sql = f"""
            SELECT 
                content,
                source,
                chunk_index
            FROM {self.table_name}
            ORDER BY embedding <=> %s::vector
            LIMIT %s;
            """
            
            with conn.cursor() as cur:
                cur.execute(sql, (vec_literal, k))
                rows = cur.fetchall()
            
            # ê²°ê³¼ í¬ë§·íŒ…
            if not rows:
                conn.close()
                return ""
            
            combined_text = ""
            for i, (content, source, chunk_index) in enumerate(rows):
                combined_text += f"[ì²­í¬ {i+1}]\n{content}\n\n"
            
            conn.close()
            return combined_text
            
        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            conn.close()
            return ""
    
    def format_emotions(
        self,
        emotions: List[Dict[str, Any]]
    ) -> str:
        """
        5ê°œ emotionê³¼ scoreë¥¼ í¬ë§·íŒ…
        
        Args:
            emotions: [{"emotion": "ìŠ¬í””", "score": 0.85}, ...] í˜•ì‹ì˜ ë¦¬ìŠ¤íŠ¸
        
        Returns:
            í¬ë§·íŒ…ëœ ê°ì • ì •ë³´ ë¬¸ìì—´
        """
        if not emotions:
            return "ê°ì • ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        emotion_lines = []
        for i, emo in enumerate(emotions[:5], 1):  # ìµœëŒ€ 5ê°œë§Œ ì‚¬ìš©
            emotion = emo.get("emotion", "ì•Œ ìˆ˜ ì—†ìŒ")
            score = emo.get("score", 0.0)
            emotion_lines.append(f"{i}. {emotion}: {score:.2f}")
        
        return "\n".join(emotion_lines)
    
    def analyze_session_emotions(self, session_id: str) -> List[Dict[str, Any]]:
        """
        ì„¸ì…˜ ê¸°ë°˜ ê°ì • ë¶„ì„ ìˆ˜í–‰
        
        Args:
            session_id: ì„¸ì…˜ ID
        
        Returns:
            5ê°œ emotionê³¼ score ë¦¬ìŠ¤íŠ¸
        """
        # 1. ì„¸ì…˜ ì¡´ì¬ í™•ì¸
        session_info = self.session_manager.get_session_info(session_id)
        if not session_info:
            print(f"âŒ ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {session_id}")
            return []
        
        # 2. ì „ì²´ ëŒ€í™” ë‚´ì—­ ê°€ì ¸ì˜¤ê¸°
        full_conversation = self.session_manager.get_full_conversation(session_id)
        if not full_conversation:
            print(f"âŒ ì„¸ì…˜ì— ëŒ€í™” ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤: {session_id}")
            return []
        
        # 3. ì‚¬ìš©ì ë©”ì‹œì§€ë§Œ í•„í„°ë§í•˜ì—¬ í•œ ì¤„ í…ìŠ¤íŠ¸ë¡œ í•©ì¹˜ê¸°
        combined_text = self.emotion_service.combine_conversation_text(full_conversation)
        if not combined_text or not combined_text.strip():
            print(f"âŒ ì‚¬ìš©ì ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤: {session_id}")
            return []
        
        # 4. ê°ì • ë¶„ì„ (ìƒìœ„ 5ê°œ)
        print(f"ğŸ˜Š ì„¸ì…˜ '{session_id}'ì˜ ê°ì • ë¶„ì„ ì¤‘...")
        emotion_results = self.emotion_service.analyze_emotions(combined_text, top_k=5)
        
        if not emotion_results:
            print(f"âš ï¸  ê°ì • ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤: {session_id}")
            return []
        
        print(f"âœ… ê°ì • ë¶„ì„ ì™„ë£Œ: {len(emotion_results)}ê°œ ê°ì • ê°ì§€")
        return emotion_results
    
    def generate_task_from_session(
        self,
        session_id: str,
        user_query: str,
        k_results: int = 2
    ) -> Dict[str, Any]:
        """
        ì„¸ì…˜ ê¸°ë°˜ìœ¼ë¡œ ê³¼ì œ ìƒì„± (ì „ì²´ ì²´ì¸ - LangChain)
        
        Args:
            session_id: ì„¸ì…˜ ID
            user_query: ì‚¬ìš©ì ì§ˆë¬¸
            k_results: ê²€ìƒ‰í•  ë…¼ë¬¸ ì²­í¬ ê°œìˆ˜
        
        Returns:
            {
                "task": "ê³¼ì œ ë‚´ìš©",
                "core_effect": "í•µì‹¬ íš¨ê³¼",
                "sources": ["ì²­í¬1", "ì²­í¬2", ...],
                "emotions": [...]
            }
        """
        # 1. ì„¸ì…˜ ê¸°ë°˜ ê°ì • ë¶„ì„
        emotions = self.analyze_session_emotions(session_id)
        
        if not emotions:
            return {
                "task": "",
                "core_effect": "",
                "sources": [],
                "emotions": [],
                "error": "ì„¸ì…˜ì—ì„œ ê°ì •ì„ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }
        
        # 2. ë…¼ë¬¸ ì²­í¬ ê²€ìƒ‰
        print(f"ğŸ” ì¿¼ë¦¬: '{user_query}'ì— ëŒ€í•´ ë…¼ë¬¸ ì²­í¬ {k_results}ê°œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤...")
        context_text = self.search_thesis_chunks(user_query, k=k_results)
        
        if not context_text:
            return {
                "task": "",
                "core_effect": "",
                "sources": [],
                "emotions": emotions,
                "error": "ë…¼ë¬¸ ì²­í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }
        
        # 3. ê°ì • ì •ë³´ í¬ë§·íŒ…
        emotions_info = self.format_emotions(emotions)
        
        # 4. LangChain ì²´ì¸ ì‹¤í–‰
        print("ğŸ¤– LangChainìœ¼ë¡œ ê³¼ì œ ìƒì„± ì¤‘...")
        try:
            response = self.chain.invoke({
                "user_query": user_query,
                "emotions_info": emotions_info,
                "context_text": context_text
            })
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°)
                json_text = response.strip()
                if json_text.startswith("```json"):
                    json_text = json_text[7:]
                if json_text.startswith("```"):
                    json_text = json_text[3:]
                if json_text.endswith("```"):
                    json_text = json_text[:-3]
                json_text = json_text.strip()
                
                result = json.loads(json_text)
                
                return {
                    "task": result.get("task", ""),
                    "core_effect": result.get("core_effect", ""),
                    "sources": context_text.split("\n\n")[:k_results],
                    "emotions": emotions
                }
            except json.JSONDecodeError:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ ë°˜í™˜
                print("âš ï¸  JSON íŒŒì‹± ì‹¤íŒ¨, ì›ë³¸ í…ìŠ¤íŠ¸ ë°˜í™˜")
                return {
                    "task": response,
                    "core_effect": "",
                    "sources": context_text.split("\n\n")[:k_results],
                    "emotions": emotions,
                    "raw_response": response
                }
                
        except Exception as e:
            print(f"âŒ ê³¼ì œ ìƒì„± ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return {
                "task": "",
                "core_effect": "",
                "sources": [],
                "emotions": emotions,
                "error": str(e)
            }


# ============================================
# ì‹±ê¸€í†¤ íŒ¨í„´
# ============================================
_task_generator_instance: Optional[TaskGeneratorService] = None

def get_task_generator_service() -> TaskGeneratorService:
    """
    Task Generator ì„œë¹„ìŠ¤ ì˜ì¡´ì„± ì£¼ì… (ì‹±ê¸€í†¤)
    """
    global _task_generator_instance
    
    if _task_generator_instance is None:
        _task_generator_instance = TaskGeneratorService()
    
    return _task_generator_instance

def reset_task_generator_service():
    """
    Task Generator ì„œë¹„ìŠ¤ ë¦¬ì…‹ (ì¬ì´ˆê¸°í™”ìš©)
    """
    global _task_generator_instance
    _task_generator_instance = None

